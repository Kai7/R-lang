---
title: "homework2"
author: "0556078"
date: "October 19, 2016"
output: html_document
---

#### Question 1:
```{r}
url <- "http://ghuang.stat.nctu.edu.tw/course/statmethods16/files/data/femaleControlsPopulation.csv" 
filename <- basename(url)
download.file(url, destfile=filename)
x <- unlist( read.csv(filename) )
```

1.a
Ans: 23.8934
```{r}
round(mean(x),4)
```

1.b
Ans: 0.2706
```{r}
set.seed(1)
round(abs(mean(sample(x, 5)) - mean(x)), 4)
```

1.c
Ans: 1.4334
```{r}
set.seed(5)
round(abs(mean(sample(x, 5)) - mean(x)), 4)
```

1.d
Ans: C)Because the average of the samples is a random variable.

1.e
Ans: 49.8%
```{r}
set.seed(1)
smp <- c()
for(i in c(1:1000)){
  smp <- c(smp,mean(sample(x, 5)))
}
mean((smp-mean(x)) > 1 | (smp-mean(x)) < -1)
```

1.f
Ans: 49.76%
```{r}
set.seed(1)
smp <- c()
for(i in c(1:10000)){
  smp <- c(smp,mean(sample(x, 5)))
}
mean((smp-mean(x)) > 1 | (smp-mean(x)) < -1)
```

1.g
Ans: 1.1%
```{r}
set.seed(1)
smp <- c()
for(i in c(1:1000)){
  smp <- c(smp,mean(sample(x, 50)))
}
mean((smp-mean(x))>1)
```

1.h
Ans: B)They both look roughly normal, but with a sample size of 50 the spread is smaller.

1.i
Ans: 97.6%
```{r}
mean(smp>=23 & smp<=25)
```

1.j
Ans: 97.66%
```{r}
round(pnorm(25,mean=23.9,sd=0.43) - pnorm(23,mean=23.9,sd=0.43), 4)
```

#### Question 2:
```{r}
url <- "http://ghuang.stat.nctu.edu.tw/course/statmethods16/files/data/mice_pheno.csv" 
filename <- basename(url)
download.file(url, destfile=filename)
dat <- na.omit( read.csv(filename) )
```

2.a
Ans: 68.27%
```{r}
round(pnorm(1) - pnorm(-1), 4)
```

2.b
Ans: 95.45%
```{r}
round(pnorm(2) - pnorm(-2), 4)
```

2.c
Ans: 99.73%
```{r}
round(pnorm(3) - pnorm(-3), 4)
```

2.d
Ans: 69.51%
```{r}
library(rafalib)
y <- dat$Bodyweight[dat$Diet == "chow" & dat$Sex == "M"]
u_y <- mean(y)
var_y <- popvar(y) # equal to mean((y-mean(y))^2)
sd_y <- popsd(y)   # equal to sqrt(popvar(y))
round(mean(y>u_y-sd_y & y<u_y+sd_y), 4)
```

2.e
Ans: 94.62%
```{r}
round(mean(y>u_y-2*sd_y & y<u_y+2*sd_y), 4)
```

2.f
Ans: 99.1%
```{r}
round(mean(y>u_y-3*sd_y & y<u_y+3*sd_y), 4)
```

2.g
Ans: C) The mouse weights are well approximated by the normal distribution, although the larger values (right tail) are larger than predicted by the normal. This is consistent with the differences seen between question c and f.
```{r}
qqnorm(y)
qqline(y, col=2)
```


2.h
Ans: B)This just happens to be how nature behaves. Perhaps the result of many biological factors averaging out.
```{r}
par(mfrow = c(2, 2))
y <- dat$Bodyweight[dat$Diet == "chow" & dat$Sex == "M"]
qqnorm(y, main = "Sex:male , diet:chow");qqline(y, col=2)
y <- dat$Bodyweight[dat$Diet == "hf" & dat$Sex == "M"]
qqnorm(y, main = "Sex:male , diet:hf");qqline(y, col=2)
y <- dat$Bodyweight[dat$Diet == "chow" & dat$Sex == "F"]
qqnorm(y, main = "Sex:female , diet:chow");qqline(y, col=2)
y <- dat$Bodyweight[dat$Diet == "hf" & dat$Sex == "F"]
qqnorm(y, main = "Sex:female , diet:hf");qqline(y, col=2)
```


2.i
Ans: 30.9558
```{r}
y <- dat$Bodyweight[dat$Diet == "chow" & dat$Sex == "M"]
#sampmean <- function(sp_size, pop){mean(sample(pop, sp_size))}
sampfm <- function(rp_num, sp_size, pop){
  set.seed(1)
  replicate(rp_num, mean(sample(pop, sp_size)))
  #replicate(rp_num, sampmean(sp_size, pop))
}
Y_avg <- sampfm(10000, 25, y)
par(mfrow = c(1, 2))
hist(Y_avg)
qqnorm(Y_avg);qqline(Y_avg, col=2)
round(mean(Y_avg), 4)
```

2.j
Ans: 0.8368
```{r}
round(popsd(Y_avg), 4)
```

2.k
Ans: D)popsd(y)/sqrt(25)
```{r}
round(popsd(y)/sqrt(25), 4)
```

2.l
Ans: 9.64%
```{r}
sampfsd <- function(rp_num, sp_size, pop){
  set.seed(1)
  replicate(rp_num, sd(sample(pop, sp_size)))
}
Y_sd <- sampfsd(10000, 25, y)
round(mean(Y_sd < 3.5), 4)
```

#### Question 3:
3.a
Ans: 4.24%
```{r}
ns <- 100; Nrp <- 10000
rolldice <- function(rp_num, sp_size){
  set.seed(1)
  replicate(rp_num, sample(c(1:6), sp_size, replace = TRUE))
}
X <- rolldice(Nrp, ns)
p <- 1/6; 
clt_m <- p; clt_sd <- sqrt(p*(1-p)/ns)
Z <- (colMeans(X == 6) - clt_m) / clt_sd
mean(abs(Z) > 2) # CTL says the result approximate 1 - (pnorm(2) - pnorm(-2))

##Another version for this experiment 
#n <- 100; N <- 100000; p <- 1/6
#X <- rbinom(N, n, p)
#Z <- (X/n - p) / sqrt(p*(1-p)/n)
#mean(abs(Z) > 2)
```

3.b
Ans: B) p=0.5 and n=30
```{r}
#qqnorm(Z); qqline(Z, col = 2)
flexrolldice <- function(N, n, r){
  set.seed(1)
  replicate(N, sample(c(1:r), n, replace = TRUE) == 1)
}
N <- 10000
pp <- c(0.5, 0.5, 0.01, 0.01); nn <- c(5, 30, 30, 100)
par(mfrow = c(2, 2))
for(i in c(1:4)){
  X <- flexrolldice(N, nn[i], 1/pp[i])
  Z <- (colMeans(X) - pp[i]) / sqrt(pp[i]*(1-pp[i])/nn[i])
  title <- paste0("p=",pp[i]," n=",nn[i])
  qqnorm(Z, main = title); qqline(Z, col = 2)
}

##Another version for this experiment 
#N <- 10000
#pp <- c(0.5, 0.5, 0.01, 0.01); nn <- c(5, 30, 30, 100)
#par(mfrow = c(2, 2))
#for(i in c(1:4)){
#  X <- rbinom(N, nn[i], pp[i])
#  Z <- (X/nn[i] - pp[i]) / sqrt(pp[i]*(1-pp[i])/nn[i])
#  title <- paste0("p=",pp[i]," n=",nn[i])
#  qqnorm(Z, main = title); qqline(Z, col = 2)
#}
```


#### Question 4:
```{r}
url <- "http://ghuang.stat.nctu.edu.tw/course/statmethods16/files/data/babies.txt"
filename <- basename(url)
download.file(url, destfile=filename)
babies <- read.table("babies.txt", header=TRUE)

require(dplyr)
bwt.nonsmoke <- filter(babies, smoke == 0) %>% select(bwt) %>% unlist()
bwt.smoke <- filter(babies, smoke == 1) %>% select(bwt) %>% unlist()

require(rafalib)
mean(bwt.nonsmoke) - mean(bwt.smoke)
popsd(bwt.nonsmoke)
popsd(bwt.smoke)
```

4.a
Ans: 2.1209
```{r}
N <- 25
set.seed(1)
dat.ns <- sample(bwt.nonsmoke, N)
dat.s <- sample(bwt.smoke, N)
tval <- (mean(dat.ns) - mean(dat.s)) / sqrt(var(dat.ns)/N + var(dat.s)/N)
round(tval, 4)
#p_val <- 1-(pt(abs(tval), df = 2*(N-1)) - pt(-abs(tval), 2*(N-1)))
```

4.b
Ans: D)2*pnorm(-abs(tval))
```{r}
2*pnorm(-abs(tval))
```

4.c
Ans: 12.0478
```{r}
round(qnorm(0.995)*sqrt(var(dat.ns)/N + var(dat.s)/N), 4)
```

4.d
Ans: 12.5453
```{r}
round(qt(0.995, df = 2*(N-1))*sqrt(var(dat.ns)/N + var(dat.s)/N), 4)
```

4.e
Ans: C)N and thus the degrees of freedom is large enough to make the normal and t distributions very similar.

4.f
Ans: 0.1049
```{r}
N <- 5
set.seed(1)
dat.ns <- sample(bwt.nonsmoke, N)
dat.s <- sample(bwt.smoke, N)
tval <- (mean(dat.ns) - mean(dat.s)) / sqrt(var(dat.ns)/N + var(dat.s)/N)
p_val <- 1-(pt(abs(tval), df = 2*(N-1)) - pt(-abs(tval), 2*(N-1)))
round(p_val, 4)
```

4.g
Ans: 9.84%
```{r}
N <- 10000; n <- 5
bwt.reject <- function(n, alpha = 0.05){
  X.ns <- sample(bwt.nonsmoke, n)
  X.s <- sample(bwt.smoke, n)
  p_val <- t.test(X.ns, X.s)$p.value
  return(p_val < alpha)
}
a <- 0.05
bwt.sampling_rej <- function(N, n, a){
  set.seed(1)
  replicate(N, bwt.reject(n, alpha = a))
}
X <- bwt.sampling_rej(N, n, a)
round(mean(X), 4)
```

4.h
Ans: when alpha = 0.05, n = 60, the power, 78.78%, is about 80%.
```{r}
nn <- c(30, 60, 90, 120)
for(i in c(1:4)){
  X <- bwt.sampling_rej(N, nn[i], a)
  cat(paste0("when n = ",nn[i],",\t power = ", mean(X)),"\n")
}
cat(paste0("at alpha = ",a,"\n"))
```

4.i
Ans: when alpha = 0.01, n = 90, the power, 79.69%, is about 80%.
```{r}
a <- 0.01
for(i in c(1:4)){
  X <- bwt.sampling_rej(N, nn[i], a)
  cat(paste0("when n = ",nn[i],",\t power = ", mean(X)),"\n")
}
cat(paste0("at alpha = ",a,"\n"))
```